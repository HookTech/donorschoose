{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0a3abf6f-c72d-41a9-ad52-e58e9c14966d",
    "_uuid": "309690d372d6a94725e46793195d4f8a8ef239da"
   },
   "source": [
    "# DonorsChoose: Donor-Project Matching with Recommender Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import pandas as pd\n",
    "import math\n",
    "import random\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from scipy.sparse.linalg import svds\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "# Any results you write to the current directory are saved as output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "source": [
    "## The Problem\n",
    "\n",
    "DonorsChoose.org has funded over 1.1 million classroom requests through the support of 3 million donors, the majority of whom were making their first-ever donation to a public school. If DonorsChoose.org can motivate even a fraction of those donors to make another donation, that could have a huge impact on the number of classroom requests fulfilled. A good solution will enable DonorsChoose.org to build targeted email campaigns recommending specific classroom requests to prior donors. \n",
    "\n",
    "## The Strategy: Recommender systems (RecSys)\n",
    "\n",
    "I consider this task a recommender system (RecSys) problem. Donors are similar to users or customers of a online platform providing various products. Let's take a music site for example: when a user named Emma listened to one or more songs at our site, we will be able to recommend more songs to her based on her listening history and the listening history of people who are similar to her.  Similarly, once a donor named Alice donated to one or more projects at DonorsChoose.org, we will be able to recommend more projects to her based on her donation history and the donation history of other donors who are similar to her. \n",
    "\n",
    "Therefore, I propose the following three approaches to solve this problem: \n",
    "\n",
    "* **Content-Based Filtering**: This method uses only information about the description and attributes of the projects donors has previously donated to when modeling the donor's preferences. In other words, these algorithms try to recommend projects that are similar to those that a donor has donated to in the past.  In particular, various candidate projects are compared with projects the donor has donated to, and the best-matching projects will be recommended.\n",
    "\n",
    "* **Collaborative Filtering**: This method makes automatic predictions (filtering) about the preference of a donor by collecting preferences from many other donors (collaborating). It predicts what a particular donor will donate to based on what projects other similar donors have donated to. The underlying assumption of the collaborative filtering approach is that if Alice and Bob have donated to the same project(s), Alice is more likely to share Bob's preference for a given project than that of a randomly chosen donor.\n",
    "\n",
    "* **Hybrid methods**: Most companies like Netflix and Hulu use a hybrid approach in their recommendation models, which provide recommendation based on the combination of what content a user like in the past as well as what other similar user like. Recent research has demonstrated that a hybrid approach that combines collaborative filtering and content-based filtering could be more effective than both approaches in some cases. These hybrid methods can also be used to overcome some of the common problems in recommender systems such as cold start and the sparsity problem.\n",
    "\n",
    "## 0. Pre-processing\n",
    "\n",
    "Before getting into the recommender systems, we will load and preprocess our datasets. The next code block is hidden in the notebook mode to facilitate reading, but the code creates two datasets: \"projects\" contains all project-related information, while \"donations_df\" contains donations- and donors-related information.  To make sure the code runs smoothly in Kaggle kernel, I turned on the **test mode** to only keep 10000 donation events in the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9957bb29-08f6-497b-bb98-384581160cc8",
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "_uuid": "5bba1736be81bc8944ad43da0de4add0f81404aa"
   },
   "outputs": [],
   "source": [
    "# Set up test mode to save some time\n",
    "test_mode = True\n",
    "\n",
    "chunk_size=10*6\n",
    "\n",
    "donations_file_path = os.getcwd() + '/io/Donations.csv'\n",
    "projects_file_path = os.getcwd() + '/io/Projects.csv'\n",
    "donors_file_path = os.getcwd() + '/io/Donors.csv'\n",
    "\n",
    "# Read datasets\n",
    "projects = pd.read_csv(projects_file_path,sep=',',header=0,keep_default_na=True,chunksize=chunk_size,iterator=True).get_chunk(10**5)\n",
    "donations = pd.read_csv(donations_file_path,sep=',',header=0,keep_default_na=True,chunksize=chunk_size,iterator=True).get_chunk(10**5)\n",
    "donors = pd.read_csv(donors_file_path,sep=',',header=0,keep_default_na=True,chunksize=chunk_size,iterator=True).get_chunk(10**5)\n",
    "\n",
    "# projects = pd.read_csv(projects_file_path,sep=',',header=0,keep_default_na=True)\n",
    "# donations = pd.read_csv(donations_file_path,sep=',',header=0,keep_default_na=True)\n",
    "# donors = pd.read_csv(donors_file_path,sep=',',header=0,keep_default_na=True)\n",
    "\n",
    "print(projects.shape)\n",
    "print(donations.shape)\n",
    "print(donors.shape)\n",
    "\n",
    "#this piece of code converts Project_ID which is a 32-bit Hex int digits 10-1010\n",
    "# create column \"project_id\" with sequential integers\n",
    "f=len(projects)\n",
    "projects['project_id'] = np.nan\n",
    "g = list(range(10,f+10))\n",
    "g = pd.Series(g)\n",
    "projects['project_id'] = g.values\n",
    "\n",
    "# Merge datasets\n",
    "donations = donations.merge(donors, on=\"Donor ID\", how=\"left\")\n",
    "df = donations.merge(projects,on=\"Project ID\", how=\"left\")\n",
    "\n",
    "# only load a few lines in test mode\n",
    "if test_mode:\n",
    "    df = df.head(10000)\n",
    "\n",
    "print(df.shape)\n",
    "donations_df = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cd2df18f-7a7d-4854-a4b1-8c6cbbb58b7e",
    "_uuid": "d95d5af01f5b4d9dcc36a5fe4993726cc104cbf7"
   },
   "source": [
    "Before modeling, we need to measure the relation strength between a donor and a project. Although most donors only donate once in the dataset, there are donors who donated to the same project multiple times, and users who donated to multiple projects. The donation amount also varies. To better measure this strength, we combine the times and amounts of donations, and create a new dataset containing unique donation relations between a donor, a project, and the relation strength.  The hidden code block will output the number of projects and unique donor-project donation events:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "6bd3aafc-1553-4e88-890c-7f71cf655638",
    "_kg_hide-input": true,
    "_uuid": "8873669dcee74d776bcdf59d06f911de634c9dfc"
   },
   "outputs": [],
   "source": [
    "# Deal with missing values\n",
    "donations[\"Donation Amount\"] = donations[\"Donation Amount\"].fillna(0)\n",
    "\n",
    "# Define event strength as the donated amount to a certain project\n",
    "donations_df['eventStrength'] = donations_df['Donation Amount']\n",
    "\n",
    "def smooth_donor_preference(x):\n",
    "    return math.log(1+x, 2)\n",
    "    \n",
    "donations_full_df = donations_df \\\n",
    "                    .groupby(['Donor ID', 'Project ID'])['eventStrength'].sum() \\\n",
    "                    .apply(smooth_donor_preference).reset_index()\n",
    "        \n",
    "# Update projects dataset\n",
    "project_cols = projects.columns\n",
    "projects = df[project_cols].drop_duplicates()\n",
    "\n",
    "print('# of projects: %d' % len(projects))\n",
    "print('# of unique user/project donations: %d' % len(donations_full_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "c5ba5d2c-0a91-4064-854e-01eb17f7a9b8",
    "_uuid": "b27b18a2338bcd8e8046f71914aa127bdc2e3463"
   },
   "source": [
    "Apparently, our test mode with 10000 donation events contains 1889 projects and 8648 unique user-project donations. We can also take a look at the first five rows of our donor-project dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "e6173bfc-1009-45ef-a83e-e75e9b553f6d",
    "_uuid": "867d1671f1a3ff24c1354682826201c316c6b23a"
   },
   "outputs": [],
   "source": [
    "# donations_full_df.head()\n",
    "np.sum([1,3,4],axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9c3da661-50d2-4ac7-b12f-35f93509ed6f",
    "_uuid": "7e727b6ecdbcffc2953b25d9164a452ae0ca4d25"
   },
   "source": [
    "To evaluate our models, we will split the donation dataset into training and validation sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "14aba2d3-5a10-4f71-9451-866240c0b7cf",
    "_uuid": "ecac4d07a8d1dbd96677496a4d3dfbf0e2149f6a"
   },
   "outputs": [],
   "source": [
    "donations_train_df, donations_test_df = train_test_split(donations_full_df,\n",
    "                                   test_size=0.20,\n",
    "                                   random_state=42)\n",
    "\n",
    "print('# donations on Train set: %d' % len(donations_train_df))\n",
    "print('# donations on Test set: %d' % len(donations_test_df))\n",
    "\n",
    "#Indexing by Donor Id to speed up the searches during evaluation\n",
    "donations_full_indexed_df = donations_full_df.set_index('Donor ID')\n",
    "donations_train_indexed_df = donations_train_df.set_index('Donor ID')\n",
    "donations_test_indexed_df = donations_test_df.set_index('Donor ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "055e4e22-5815-4e4b-a6bc-7552598cc6c5",
    "_uuid": "e2f26de1df60ccf75f0cde45177becdf3e9feeca"
   },
   "source": [
    "We are ready to move on to the recommender system models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "c827e13a-e2a6-4e36-b6dc-9f9b155265ad",
    "_uuid": "9d8a8cc2ef297a902532377142dd38d851a9c227"
   },
   "outputs": [],
   "source": [
    "## 1. Content-Based Filtering model\n",
    "\n",
    "The first approach, the Content-Based Filtering method, is to find projects that are similar to the project(s) that a donor has already donated to. We can calculate the similarity between projects based on metadata (project type, project category, grade level, resource category, cost, school location, etc) and/or text features extracted from the project titles and descriptions. In this solution, I mainly demonstrate how to implement the latter approach. \n",
    "\n",
    "We will use a very popular technique, TF-IDF, to extract information from project title and descriptions. TF-IDF converts unstructured text into a vector structure, where each word is represented by a position in the vector, and the value measures how relevant a given word is for a project title/descriptions. It is used bo compute similarity between projects based on project titles and descriptions. \n",
    "\n",
    "### 1.1 Process text data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9abc1496-b597-4068-8725-2c7ce39aa497",
    "_kg_hide-output": true,
    "_uuid": "ea4b2d354ea82ee9ea5a66d79ea036b58dc8a564"
   },
   "outputs": [],
   "source": [
    "# Preprocessing of text data\n",
    "textfeats = [\"Project Title\",\"Project Essay\"]\n",
    "for cols in textfeats:\n",
    "    projects[cols] = projects[cols].astype(str) \n",
    "    projects[cols] = projects[cols].astype(str).fillna('') # FILL NA\n",
    "    projects[cols] = projects[cols].str.lower() # Lowercase all text, so that capitalized words dont get treated differently\n",
    " \n",
    "text = projects[\"Project Title\"] + ' ' + projects[\"Project Essay\"]\n",
    "vectorizer = TfidfVectorizer(strip_accents='unicode',\n",
    "                             analyzer='word',\n",
    "                             lowercase=True, # Convert all uppercase to lowercase\n",
    "                             stop_words='english', # Remove commonly found english words ('it', 'a', 'the') which do not typically contain much signal\n",
    "                             max_df = 0.9, # Only consider words that appear in fewer than max_df percent of all documents\n",
    "                             # max_features=5000 # Maximum features to be extracted                    \n",
    "                            )                        \n",
    "project_ids = projects['Project ID'].tolist()\n",
    "tfidf_matrix = vectorizer.fit_transform(text)\n",
    "tfidf_feature_names = vectorizer.get_feature_names()\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "f41681f8-9e45-4561-95f9-d9613c53b1c6",
    "_uuid": "d901881d9d02eadf66916bbd7518f91df0c7b31f"
   },
   "source": [
    "### 1.2 Build donor profile\n",
    "\n",
    "To build a donor's profile, we take all the projects the donor has donated to and average them. The average is weighted by the event strength based on donation times and amount. In other words, the project the donor has donated more money will have a higher strength in the final donor profile. \n",
    "\n",
    "The next code chunk builds donor profiles for all donors in our dataset, and return the total number of donors with profiles. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "137b2edc-9953-41a7-bb72-21484b2b1313",
    "_uuid": "c305beb5e4b9d170b8b757dec2502a41856fd46d"
   },
   "outputs": [],
   "source": [
    "def get_project_profile(project_id):\n",
    "    idx = project_ids.index(project_id)\n",
    "    project_profile = tfidf_matrix[idx:idx+1]\n",
    "    return project_profile\n",
    "\n",
    "def get_project_profiles(ids):\n",
    "    project_profiles_list = [get_project_profile(x) for x in np.ravel([ids])]\n",
    "    project_profiles = scipy.sparse.vstack(project_profiles_list)\n",
    "    return project_profiles\n",
    "\n",
    "def build_donors_profile(donor_id, donations_indexed_df):\n",
    "    donations_donor_df = donations_indexed_df.loc[donor_id]\n",
    "    donor_project_profiles = get_project_profiles(donations_donor_df['Project ID'])\n",
    "    donor_project_strengths = np.array(donations_donor_df['eventStrength']).reshape(-1,1)\n",
    "    print(donor_project_profiles.multiply(donor_project_strengths))\n",
    "    #Weighted average of project profiles by the donations strength\n",
    "    donor_project_strengths_weighted_avg = np.sum(donor_project_profiles.multiply(donor_project_strengths)) / (np.sum(donor_project_strengths)+1)\n",
    "    donor_profile_norm = sklearn.preprocessing.normalize(donor_project_strengths_weighted_avg)\n",
    "    return donor_profile_norm\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "def build_donors_profiles(): \n",
    "    donations_indexed_df = donations_full_df[donations_full_df['Project ID'].isin(projects['Project ID'])].set_index('Donor ID')\n",
    "    donor_profiles = {}\n",
    "    for donor_id in tqdm(donations_indexed_df.index.unique()):\n",
    "        donor_profiles[donor_id] = build_donors_profile(donor_id, donations_indexed_df)\n",
    "    return donor_profiles\n",
    "\n",
    "donor_profiles = build_donors_profiles()\n",
    "print(\"# of donors with profiles: %d\" % len(donor_profiles))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "5cb72f98-6beb-4348-85d0-b4ac58a18515",
    "_uuid": "d7b0f1314d55899819774040936097dce7a625a3"
   },
   "source": [
    "In test mode, we have built user profiles for 8015 donors. Let's take a look at one particular user's profile by displaying text tokens that are most relevant to this donor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d91ba406-39a0-418e-a1f8-19f5defc228f",
    "_uuid": "b11bd7aa14ef8a3c8e678c80075ee9b52988bcad"
   },
   "outputs": [],
   "source": [
    "mydonor1 = \"6d5b22d39e68c656071a842732c63a0c\"\n",
    "mydonor2 = \"0016b23800f7ea46424b3254f016007a\"\n",
    "mydonor1_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        donor_profiles[mydonor1].flatten().tolist()), \n",
    "                        key=lambda x: -x[1])[:10],\n",
    "                        columns=['token', 'relevance'])\n",
    "mydonor2_profile = pd.DataFrame(sorted(zip(tfidf_feature_names, \n",
    "                        donor_profiles[mydonor2].flatten().tolist()), \n",
    "                        key=lambda x: -x[1])[:10],\n",
    "                        columns=['token', 'relevance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "9f8953c0-022d-47b8-a01a-51914a4d0dfe",
    "_uuid": "6cec688556cc282d7fbb8793172b211321ad2f65"
   },
   "outputs": [],
   "source": [
    "mydonor1_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "804f4b06-1725-4465-b1db-a200f3386d20",
    "_uuid": "cd8887950874624f675f16c10c264b1e6694e99f"
   },
   "outputs": [],
   "source": [
    "mydonor2_profile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1381e4fd-a606-4ebe-873e-e333e685ba72",
    "_uuid": "99ee48951764096557d641b49361dddee83ac0cb"
   },
   "source": [
    "Apparently, our content-based recommender figures that donor 1 is more interested in music-related projects, and donor 2 is more interested in projects about planting and reading. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "afb55090-3bf6-496d-82dc-ab4305c4ed01",
    "_uuid": "0cfd7d4b077568c23d4ff9c5fc5e2e1b0cdae428"
   },
   "source": [
    "### 1.3 Build the Content-Based Recommender"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ee3e9cc0-792a-4398-9f1b-0132cc347369",
    "_uuid": "e2358ed6f547ffa3e3bb3a883210e5821c66ab19"
   },
   "source": [
    "Now it's time to build our content-based recommender: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4bede51f-2ea3-4c09-a759-c1c48e83b6b1",
    "_uuid": "e0e3da484d83df49c44813b95cf661b23980f962"
   },
   "outputs": [],
   "source": [
    "class ContentBasedRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Content-Based'\n",
    "    \n",
    "    def __init__(self, projects_df=None):\n",
    "        self.project_ids = project_ids\n",
    "        self.projects_df = projects_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def _get_similar_projects_to_donor_profile(self, donor_id, topn=1000):\n",
    "        #Computes the cosine similarity between the donor profile and all project profiles\n",
    "        cosine_similarities = cosine_similarity(donor_profiles[donor_id], tfidf_matrix)\n",
    "        #Gets the top similar projects\n",
    "        similar_indices = cosine_similarities.argsort().flatten()[-topn:]\n",
    "        #Sort the similar projects by similarity\n",
    "        similar_projects = sorted([(project_ids[i], cosine_similarities[0,i]) for i in similar_indices], key=lambda x: -x[1])\n",
    "        return similar_projects\n",
    "        \n",
    "    def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10, verbose=False):\n",
    "        similar_projects = self._get_similar_projects_to_donor_profile(donor_id)\n",
    "        #Ignores projects the donor has already donated\n",
    "        similar_projects_filtered = list(filter(lambda x: x[0] not in projects_to_ignore, similar_projects))\n",
    "        \n",
    "        recommendations_df = pd.DataFrame(similar_projects_filtered, columns=['Project ID', 'recStrength']).head(topn)\n",
    "\n",
    "        recommendations_df = recommendations_df.merge(self.projects_df, how = 'left', \n",
    "                                                    left_on = 'Project ID', \n",
    "                                                    right_on = 'Project ID')[['recStrength', 'Project ID', 'Project Title', 'Project Essay']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3e68406f-47dd-4b51-b2ab-3216a3093293",
    "_uuid": "3df9602d00812f7a0271324b8b6b825aaa301f60"
   },
   "source": [
    "Let's use this Content-Based Recommender to see what it will recommend to my donor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "8c891621-1b11-44c5-b326-1b286792fa29",
    "_uuid": "efd47d5f8caa1448078cb723e808e516f485b6c0"
   },
   "outputs": [],
   "source": [
    "cbr_model = ContentBasedRecommender(projects)\n",
    "cbr_model.recommend_projects(mydonor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b050e390-a829-4b9f-9260-71d45e9c2df2",
    "_uuid": "fc8ca6a99f32552796d4aed157044d4400a726b3"
   },
   "outputs": [],
   "source": [
    "cbr_model.recommend_projects(mydonor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "97a880c4-b425-4b78-bcd9-a93d10257638",
    "_uuid": "31767786dd69f2c7d28c157e32f542f79f8ac244"
   },
   "source": [
    "It recommends music projects to donor 1, and gardening and reading projects to donor 2. \n",
    "\n",
    "This is because our donor 1 has donated to music project(s) before,  and donor 2 has donated to gardening and reading projects; the Content-Based Recommender successfully finds similar projects for our donors based on the project titles and descriptions. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "02b7f139-6820-4d7a-8a9e-ec918f8f2bb9",
    "_uuid": "10a30ce93066aecbf737975ec44cc66be62ab84a"
   },
   "source": [
    "## 2. Collaborative Filtering Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9a19658c-1205-4afd-adc9-79ad74f01ed9",
    "_uuid": "c6c36238e24e5537f533ccf918024ac07111deec"
   },
   "source": [
    "Next, we will build a model-based Collaborative Filtering (CF) Recommender. In this approach, models are developed using machine learning algorithms to recommend project to donors. There are many model-based CF algorithms, here we adopt a latent factor model, which compresses donor-project matrix into a low-dimensional representation in terms of latent factors. A reduced presentation could be utilized for either donor-based or project-based neighborhood searching algorithms to find recommendations. Here we a use popular latent factor model named Singular Value Decomposition (SVD). \n",
    "\n",
    "### 2.1 Create the donor-project matrix\n",
    "\n",
    "We will first get the donor-project matrix and print the first five rows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "fc76a2d1-6509-4c22-b38a-85df1c29e805",
    "_uuid": "9d2e94e13d4d68faa346edd437daefec829c556b"
   },
   "outputs": [],
   "source": [
    "#Creating a sparse pivot table with donors in rows and projects in columns\n",
    "donors_projects_pivot_matrix_df = donations_full_df.pivot(index='Donor ID', \n",
    "                                                          columns='Project ID', \n",
    "                                                          values='eventStrength').fillna(0)\n",
    "\n",
    "# Transform the donor-project dataframe into a matrix\n",
    "donors_projects_pivot_matrix = donors_projects_pivot_matrix_df.as_matrix()\n",
    "\n",
    "# Get donor ids\n",
    "donors_ids = list(donors_projects_pivot_matrix_df.index)\n",
    "\n",
    "# Print the first 5 rows of the donor-project matrix\n",
    "donors_projects_pivot_matrix[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "720354c1-b4db-4e56-8654-fdc22aee5cb7",
    "_uuid": "49d75fbbaa0a160d4824d0468c1be002831ba752"
   },
   "source": [
    "Now we are ready to compresses donor-project matrix into a low-dimensional representation in terms of latent factors.\n",
    "\n",
    "### 2.2 Singular Value Decomposition (SVD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "56d314f5-3e18-405b-b12c-0f1fb4d6c29f",
    "_uuid": "09652b2ed8adc1734acad06393bf21a4450caa25"
   },
   "source": [
    "Now we will use SVD to get latent factors. After the factorization, we will try to reconstruct the original matrix by multiplying its factors. The resulting matrix is not sparse any more. It is the generated predictions for projects the donor have not yet donated to, which we will exploit for recommendations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6933e80-d0b7-496b-b507-c8903956136f",
    "_uuid": "ee855bccd4506833972b46b20406043882d7a26f"
   },
   "outputs": [],
   "source": [
    "# Performs matrix factorization of the original donor-project matrix\n",
    "# Here we set k = 20, which is the number of factors we are going to get\n",
    "# In the definition of SVD, an original matrix A is approxmated as a product A ≈ UΣV \n",
    "# where U and V have orthonormal columns, and Σ is non-negative diagonal.\n",
    "U, sigma, Vt = svds(donors_projects_pivot_matrix, k = 20)\n",
    "sigma = np.diag(sigma)\n",
    "\n",
    "# Reconstruct the matrix by multiplying its factors\n",
    "all_donor_predicted_ratings = np.dot(np.dot(U, sigma), Vt) \n",
    "\n",
    "#Converting the reconstructed matrix back to a Pandas dataframe\n",
    "cf_preds_df = pd.DataFrame(all_donor_predicted_ratings, \n",
    "                           columns = donors_projects_pivot_matrix_df.columns, \n",
    "                           index=donors_ids).transpose()\n",
    "cf_preds_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4e73ea1f-99cd-423f-aaec-30fde964c69f",
    "_uuid": "30b61c3fae2a668e733e5967eb6414cb6db5ecb9"
   },
   "source": [
    "### 2.3 Build the Collaborative Filtering Model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "1912632f-a875-4354-98d2-4577af684a68",
    "_uuid": "90a9cdca940efbc88a3ae2e474da610c2ccc16fb"
   },
   "source": [
    "We are ready to build our collaborative filtering recommender! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "4010c8a6-0071-47f7-be6a-92e67605dd08",
    "_uuid": "b67b5af5e3077d7062855f043d849c9f36c906a6"
   },
   "outputs": [],
   "source": [
    "class CFRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Collaborative Filtering'\n",
    "    \n",
    "    def __init__(self, cf_predictions_df, projects_df=None):\n",
    "        self.cf_predictions_df = cf_predictions_df\n",
    "        self.projects_df = projects_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10):\n",
    "        # Get and sort the donor's predictions\n",
    "        sorted_donor_predictions = self.cf_predictions_df[donor_id].sort_values(ascending=False) \\\n",
    "                                    .reset_index().rename(columns={donor_id: 'recStrength'})\n",
    "\n",
    "        # Recommend the highest predicted projects that the donor hasn't donated to\n",
    "        recommendations_df = sorted_donor_predictions[~sorted_donor_predictions['Project ID'].isin(projects_to_ignore)] \\\n",
    "                               .sort_values('recStrength', ascending = False) \\\n",
    "                               .head(topn)\n",
    "\n",
    " \n",
    "        recommendations_df = recommendations_df.merge(self.projects_df, how = 'left', \n",
    "                                                          left_on = 'Project ID', \n",
    "                                                          right_on = 'Project ID')[['recStrength', 'Project ID', 'Project Title', 'Project Essay']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9d1086f0-4bb8-4bc9-bf49-5e0b72fca565",
    "_uuid": "77cad26a9c23755171198829779c505389cab8fd"
   },
   "source": [
    "Let's look at its recommendations to our donor1 and donor2. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d6b29193-e9a5-47ed-ad5e-6cc766bda867",
    "_uuid": "13d3856b14cf1565c9533abcc03c6b9e6bdbff1a"
   },
   "outputs": [],
   "source": [
    "cfr_model = CFRecommender(cf_preds_df, projects)\n",
    "cfr_model.recommend_projects(mydonor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d72f24cd-7668-40b8-9d7a-a5cf11cbb16b",
    "_uuid": "4ce176fab640342353238f3a9541a96810de7caf"
   },
   "outputs": [],
   "source": [
    "cfr_model.recommend_projects(mydonor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "d4ecedcf-2e6b-4ea8-a6e5-b8165fd5d357",
    "_uuid": "4c4f41d2e5af830b32347d9ba1493382919e18a0"
   },
   "source": [
    "The recommendations are quite different this time. This is becaues the Collaborative Filtering model considers the donations made by other donors who have a similar preference to our donor. Therefore, popular projects are more likely to be seen here. \n",
    "\n",
    "## 3. Hybrid Method\n",
    "\n",
    "The third approach, the hybrid method, combines the first two approaches to try to give even better recommendations. Hybrid methods have performed better than individual approaches in many studies and have being extensively used by researchers and practioners.\n",
    "\n",
    "Let's build a very simple hybridization method, by only multiply the Content-Based score with the Collaborative-Filtering score , and ranking by the resulting hybrid score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "30f38e3d-29d7-4809-871c-d94b20ded49b",
    "_uuid": "3805514058bd13b465ea7ebf82d247bc44a1321d"
   },
   "outputs": [],
   "source": [
    "class HybridRecommender:\n",
    "    \n",
    "    MODEL_NAME = 'Hybrid'\n",
    "    \n",
    "    def __init__(self, cb_rec_model, cf_rec_model, projects_df):\n",
    "        self.cb_rec_model = cb_rec_model\n",
    "        self.cf_rec_model = cf_rec_model\n",
    "        self.projects_df = projects_df\n",
    "        \n",
    "    def get_model_name(self):\n",
    "        return self.MODEL_NAME\n",
    "        \n",
    "    def recommend_projects(self, donor_id, projects_to_ignore=[], topn=10):\n",
    "        #Getting the top-1000 Content-based filtering recommendations\n",
    "        cb_recs_df = self.cb_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore, \n",
    "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCB'})\n",
    "        \n",
    "        #Getting the top-1000 Collaborative filtering recommendations\n",
    "        cf_recs_df = self.cf_rec_model.recommend_projects(donor_id, projects_to_ignore=projects_to_ignore,  \n",
    "                                                           topn=1000).rename(columns={'recStrength': 'recStrengthCF'})\n",
    "        \n",
    "        #Combining the results by Project ID\n",
    "        recs_df = cb_recs_df.merge(cf_recs_df,\n",
    "                                   how = 'inner', \n",
    "                                   left_on = 'Project ID', \n",
    "                                   right_on = 'Project ID')\n",
    "        \n",
    "        #Computing a hybrid recommendation score based on CF and CB scores\n",
    "        recs_df['recStrengthHybrid'] = recs_df['recStrengthCB'] * recs_df['recStrengthCF']\n",
    "        \n",
    "        #Sorting recommendations by hybrid score\n",
    "        recommendations_df = recs_df.sort_values('recStrengthHybrid', ascending=False).head(topn)\n",
    "\n",
    "        recommendations_df = recommendations_df.merge(self.projects_df, how = 'left', \n",
    "                                                    left_on = 'Project ID', \n",
    "                                                    right_on = 'Project ID')[['recStrengthHybrid', \n",
    "                                                                              'Project ID', 'Project Title', \n",
    "                                                                              'Project Essay']]\n",
    "\n",
    "\n",
    "        return recommendations_df\n",
    "    \n",
    "hybrid_model = HybridRecommender(cbr_model, cfr_model, projects)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a4485ec1-3a61-460c-8b22-d960097ffc34",
    "_uuid": "a406e2381227961177ca41858c57862dbe47a330"
   },
   "source": [
    "Now let's look at the recommendations for our donor1 and donor2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "1f5b3571-069f-4817-acc7-77f84de534e8",
    "_uuid": "b036da114ba1e5075323205212073f53295f1f16"
   },
   "outputs": [],
   "source": [
    "hybrid_model.recommend_projects(mydonor1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "200a000c-0c76-4045-99f5-43896860a8ee",
    "_uuid": "8234251512c3bded0e2443a76a3b1295c0b39cdd"
   },
   "outputs": [],
   "source": [
    "hybrid_model.recommend_projects(mydonor2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d9b0242-e87a-40c2-9a83-f5d723fc017a",
    "_uuid": "e1f5c264fa6aee605dbaa98e305d377d2562d3c8"
   },
   "source": [
    "Indeed, the results are hybrid - recommendations for donor 1 include music projects as well as popular projects from donors that have similar preferences to donor1,  and recommendations for donor 2 include reading projects as well as popular projects from donors that have similar preferences to donor 2. \n",
    "\n",
    "Note that in the Content-Based Model, new projects without any donation yet will also get a chance to be recommended, while in the Collaborative Filtering Model, only projects that have already received some donation will get the chance to be recommended. In reality we may want both to happen, therefore a Hybrid Model might be more ideal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "3900c0b6568387cc99bbed0ca83c1a6cd121129e"
   },
   "source": [
    "## 4. Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4b28a63f46d71bd9a0cd122fc28734487e3c3987"
   },
   "source": [
    "In Recommender Systems, there are a set metrics commonly used for evaluation. We chose to work with **Top-N accuracy metrics**, which evaluates the accuracy of the top recommendations provided to a user, comparing to the items the user has actually interacted.  \n",
    "This evaluation method works as follows:\n",
    "\n",
    "* For each user\n",
    "    * For each item the user has interacted in test set\n",
    "        * Sample 1000 other items the user has never interacted.   \n",
    "        * Ask the recommender model to produce a ranked list of recommended items, from a set composed one interacted item and the 100 non-interacted (\"non-relevant!) items\n",
    "        * Compute the Top-N accuracy metrics for this user and interacted item from the recommendations ranked list\n",
    "* Aggregate the global Top-N accuracy metrics\n",
    "\n",
    "In the next code block, we build the model evaluator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2a72d37f7b99617ffa21a0c7ddb07ebe75d06aa4"
   },
   "outputs": [],
   "source": [
    "def get_projects_donated(donor_id, donations_df):\n",
    "    # Get the donor's data and merge in the movie information.\n",
    "    try:\n",
    "        donated_projects = donations_df.loc[donor_id]['Project ID']\n",
    "        return set(donated_projects if type(donated_projects) == pd.Series else [donated_projects])\n",
    "    except KeyError:\n",
    "        return []\n",
    "\n",
    "#Top-N accuracy metrics consts\n",
    "EVAL_RANDOM_SAMPLE_NON_INTERACTED_PROJECTS = 100\n",
    "\n",
    "class ModelEvaluator:\n",
    "\n",
    "    def get_not_donated_projects_sample(self, donor_id, sample_size, seed=42):\n",
    "        donated_projects = get_projects_donated(donor_id, donations_full_indexed_df)\n",
    "        all_projects = set(projects['Project ID'])\n",
    "        non_donated_projects = all_projects - donated_projects\n",
    "\n",
    "        #random.seed(seed)\n",
    "        non_donated_projects_sample = random.sample(non_donated_projects, sample_size)\n",
    "        return set(non_donated_projects_sample)\n",
    "\n",
    "    def _verify_hit_top_n(self, project_id, recommended_projects, topn):        \n",
    "            try:\n",
    "                index = next(i for i, c in enumerate(recommended_projects) if c == project_id)\n",
    "            except:\n",
    "                index = -1\n",
    "            hit = int(index in range(0, topn))\n",
    "            return hit, index\n",
    "\n",
    "    def evaluate_model_for_donor(self, model, donor_id):\n",
    "        #Getting the projects in test set\n",
    "        donated_values_testset = donations_test_indexed_df.loc[donor_id]\n",
    "        if type(donated_values_testset['Project ID']) == pd.Series:\n",
    "            donor_donated_projects_testset = set(donated_values_testset['Project ID'])\n",
    "        else:\n",
    "            donor_donated_projects_testset = set([donated_values_testset['Project ID']])  \n",
    "        donated_projects_count_testset = len(donor_donated_projects_testset) \n",
    "\n",
    "        #Getting a ranked recommendation list from a model for a given donor\n",
    "        donor_recs_df = model.recommend_projects(donor_id, \n",
    "                                               projects_to_ignore=get_projects_donated(donor_id, \n",
    "                                                                                    donations_train_indexed_df), \n",
    "                                               topn=100000000)\n",
    "\n",
    "        hits_at_3_count = 0\n",
    "        hits_at_5_count = 0\n",
    "        hits_at_10_count = 0\n",
    "        #For each project the donor has donated in test set\n",
    "        for project_id in donor_donated_projects_testset:\n",
    "            #Getting a random sample (100) projects the donor has not donated \n",
    "            #(to represent projects that are assumed to be no relevant to the donor)\n",
    "            non_donated_projects_sample = self.get_not_donated_projects_sample(donor_id, \n",
    "                                                                          sample_size=EVAL_RANDOM_SAMPLE_NON_INTERACTED_PROJECTS, \n",
    "                                                                              seed=42)\n",
    "\n",
    "            #Combining the current donated project with the 100 random projects\n",
    "            projects_to_filter_recs = non_donated_projects_sample.union(set([project_id]))\n",
    "\n",
    "            #Filtering only recommendations that are either the donated project or from a random sample of 100 non-donated projects\n",
    "            valid_recs_df = donor_recs_df[donor_recs_df['Project ID'].isin(projects_to_filter_recs)]                    \n",
    "            valid_recs = valid_recs_df['Project ID'].values\n",
    "            #Verifying if the current donated project is among the Top-N recommended projects\n",
    "            hit_at_3, index_at_3 = self._verify_hit_top_n(project_id, valid_recs, 3)\n",
    "            hits_at_3_count += hit_at_3\n",
    "            hit_at_5, index_at_5 = self._verify_hit_top_n(project_id, valid_recs, 5)\n",
    "            hits_at_5_count += hit_at_5\n",
    "            hit_at_10, index_at_10 = self._verify_hit_top_n(project_id, valid_recs, 10)\n",
    "            hits_at_10_count += hit_at_10\n",
    "\n",
    "        #Recall is the rate of the donated projects that are ranked among the Top-N recommended projects, \n",
    "        #when mixed with a set of non-relevant projects\n",
    "        recall_at_3 = hits_at_3_count / float(donated_projects_count_testset)\n",
    "        recall_at_5 = hits_at_5_count / float(donated_projects_count_testset)\n",
    "        recall_at_10 = hits_at_10_count / float(donated_projects_count_testset)\n",
    "\n",
    "        donor_metrics = {'hits@3_count':hits_at_3_count, \n",
    "                         'hits@5_count':hits_at_5_count, \n",
    "                          'hits@10_count':hits_at_10_count, \n",
    "                          'donated_count': donated_projects_count_testset,\n",
    "                          'recall@3': recall_at_3,\n",
    "                          'recall@5': recall_at_5,\n",
    "                          'recall@10': recall_at_10}\n",
    "        return donor_metrics\n",
    "\n",
    "    def evaluate_model(self, model):\n",
    "        #print('Running evaluation for donors')\n",
    "        people_metrics = []\n",
    "        for idx, donor_id in enumerate(list(donations_test_indexed_df.index.unique().values)):\n",
    "            #if idx % 100 == 0 and idx > 0:\n",
    "            #    print('%d donors processed' % idx)\n",
    "            donor_metrics = self.evaluate_model_for_donor(model, donor_id)  \n",
    "            donor_metrics['_donor_id'] = donor_id\n",
    "            people_metrics.append(donor_metrics)\n",
    "        print('%d donors processed' % idx)\n",
    "\n",
    "        detailed_results_df = pd.DataFrame(people_metrics) \\\n",
    "                            .sort_values('donated_count', ascending=False)\n",
    "        \n",
    "        global_recall_at_3 = detailed_results_df['hits@3_count'].sum() / float(detailed_results_df['donated_count'].sum())\n",
    "        global_recall_at_5 = detailed_results_df['hits@5_count'].sum() / float(detailed_results_df['donated_count'].sum())\n",
    "        global_recall_at_10 = detailed_results_df['hits@10_count'].sum() / float(detailed_results_df['donated_count'].sum())\n",
    "        \n",
    "        global_metrics = {'modelName': model.get_model_name(),\n",
    "                          'recall@3': global_recall_at_3,\n",
    "                          'recall@5': global_recall_at_5,\n",
    "                          'recall@10': global_recall_at_10}    \n",
    "        return global_metrics, detailed_results_df\n",
    "    \n",
    "model_evaluator = ModelEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a80a9e48347c9e1a00c73a1896daf95026b9cff7"
   },
   "source": [
    "Evaluate the Content-Based Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0cd59d86c2184cd7135ad22b706c690218a7dc49"
   },
   "outputs": [],
   "source": [
    "print('Evaluating Content-Based Filtering model...')\n",
    "cb_global_metrics, cb_detailed_results_df = model_evaluator.evaluate_model(cbr_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cb_global_metrics)\n",
    "cb_detailed_results_df = cb_detailed_results_df[['_donor_id', 'donated_count', \"hits@3_count\", 'hits@5_count','hits@10_count', \n",
    "                                                'recall@3','recall@5','recall@10']]\n",
    "cb_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "e2ae28a9b5fb476e3be9da0990ef3633501a648d"
   },
   "source": [
    "Evaluate the Collaborative Filtering Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9ae03fe24dba646f13d9f6368d2321a5463994ba"
   },
   "outputs": [],
   "source": [
    "print('Evaluating Collaborative Filtering (SVD Matrix Factorization) model...')\n",
    "cf_global_metrics, cf_detailed_results_df = model_evaluator.evaluate_model(cfr_model)\n",
    "print('\\nGlobal metrics:\\n%s' % cf_global_metrics)\n",
    "cf_detailed_results_df = cf_detailed_results_df[['_donor_id', 'donated_count', \"hits@3_count\", 'hits@5_count','hits@10_count', \n",
    "                                                'recall@3','recall@5','recall@10']]\n",
    "cf_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5a8ffbaeec8935040cd48b428995df85c47dc9d1"
   },
   "source": [
    "Evaluating the Hybrid Model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b74978a62d6db9a76264a0ec681034a129099fb9"
   },
   "outputs": [],
   "source": [
    "print('Evaluating Hybrid model...')\n",
    "hybrid_global_metrics, hybrid_detailed_results_df = model_evaluator.evaluate_model(hybrid_model)\n",
    "print('\\nGlobal metrics:\\n%s' % hybrid_global_metrics)\n",
    "hybrid_detailed_results_df = hybrid_detailed_results_df[['_donor_id', 'donated_count', \"hits@3_count\", 'hits@5_count','hits@10_count', \n",
    "                                                'recall@3','recall@5','recall@10']]\n",
    "hybrid_detailed_results_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a4bdf120318c90f75340a6fc8be4248257578bd6"
   },
   "source": [
    "Comparing three models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "93ddb92a9fd284051a6cf06a5e9d451e56bc765a"
   },
   "outputs": [],
   "source": [
    "global_metrics_df = pd.DataFrame([cf_global_metrics, \n",
    "                                  cb_global_metrics, \n",
    "                                  hybrid_global_metrics]).set_index('modelName')\n",
    "global_metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c7e0b5ff81e21406c79f69f5e2fdbf2faf0b7799"
   },
   "source": [
    "The content-based model works best for our testing mode sample. \n",
    "\n",
    "Let's check for the donor who has donated to 7 projects. We'll check what this donor has actually donated to, and what our three recommender would recommend to him/her. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4594730c2afdb4eb3dba88e4383d48c2cced20e7"
   },
   "outputs": [],
   "source": [
    "donor = \"a0e1d358aa17745ff3d3f4e4909356f3\"\n",
    "project_list = get_projects_donated(donor, donations_test_indexed_df)\n",
    "donated = projects[projects[\"Project ID\"].isin(project_list)][\"Project Title\"].tolist()\n",
    "\n",
    "cbr_rec = cbr_model.recommend_projects(donor).head(7)[\"Project Title\"].tolist()\n",
    "cfr_rec = cfr_model.recommend_projects(donor).head(7)[\"Project Title\"].tolist()\n",
    "hybrid_rec = hybrid_model.recommend_projects(donor).head(7)[\"Project Title\"].tolist()\n",
    "\n",
    "d = {'Donated': donated, \n",
    "     'Content-Based': cbr_rec,\n",
    "    'Collaborative-Filtering': cfr_rec,\n",
    "    'Hybrid': hybrid_rec}\n",
    "pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "53e7d4d6df73f374be9b40fe1f66a4db8c877b6e"
   },
   "source": [
    "Apparently, this donor is highly interested in reading projects, and the Content-Based recommender successfully captured this.  The hybrid method is not that bad either. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7462096f-9143-48a2-bc18-012aa4898716",
    "_uuid": "70e0b50f4ecb962ce328b57f503b2e5da180d809"
   },
   "source": [
    "I plan to finish this solution by the following roadmap, so please stay tuned. \n",
    "\n",
    "Thank you for reading and please let me know if you have any suggestion or feedback! \n",
    "\n",
    "## Roadmap\n",
    "## 5. Adjusting\n",
    "##\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "170f080c-5934-4c30-8eb6-82a544478900",
    "_uuid": "5285d099311b65e8fd789b05c93adeeed4c5084a"
   },
   "source": [
    "## References\n",
    "\n",
    "Most of the codes and part of the text is based on [this great kernel](https://www.kaggle.com/gspmoreira/recommender-systems-in-python-101) written by Gabriel Moreira. Thank you so much!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
